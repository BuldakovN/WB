{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сравнение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, balanced_accuracy_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = [\n",
    "    'catboost_baseline.model',\n",
    "    'catboost_full.model',\n",
    "    'catboost_with_text.model',\n",
    "    'catboost_with_id.model',\n",
    "    'catboost_with_text-class.model',\n",
    "    'catboost_with_text_text-class.model',\n",
    "    'catboost_with_text.model'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../data/unbalanced_data/train_data.csv')\n",
    "Y_train = X_train['label']\n",
    "\n",
    "X_valid = pd.read_csv('../data/unbalanced_data/valid_data.csv')\n",
    "Y_valid = X_valid['label']\n",
    "\n",
    "X_test = pd.read_csv('../data/unbalanced_data/test_data.csv')\n",
    "Y_test = X_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_SILENT=True\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_SILENT=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./catboost_baseline.model\n",
      "Взвешанная, все 0 0.624073732718894\n",
      "Невзвешанная, все 0 0.0\n",
      "Взвешанная, все 1 0.11027848101265822\n",
      "Невзвешанная, все 1 0.4177215189873418\n",
      "./catboost_full.model\n",
      "Взвешанная, все 0 0.624073732718894\n",
      "Невзвешанная, все 0 0.0\n",
      "Взвешанная, все 1 0.11027848101265822\n",
      "Невзвешанная, все 1 0.4177215189873418\n",
      "./catboost_with_text.model\n",
      "Взвешанная, все 0 0.624073732718894\n",
      "Невзвешанная, все 0 0.0\n",
      "Взвешанная, все 1 0.11027848101265822\n",
      "Невзвешанная, все 1 0.4177215189873418\n",
      "./catboost_with_id.model\n",
      "Взвешанная, все 0 0.624073732718894\n",
      "Невзвешанная, все 0 0.0\n",
      "Взвешанная, все 1 0.11027848101265822\n",
      "Невзвешанная, все 1 0.4177215189873418\n",
      "./catboost_with_text-class.model\n",
      "Взвешанная, все 0 0.624073732718894\n",
      "Невзвешанная, все 0 0.0\n",
      "Взвешанная, все 1 0.11027848101265822\n",
      "Невзвешанная, все 1 0.4177215189873418\n",
      "./catboost_with_text_text-class.model\n",
      "Взвешанная, все 0 0.624073732718894\n",
      "Невзвешанная, все 0 0.0\n",
      "Взвешанная, все 1 0.11027848101265822\n",
      "Невзвешанная, все 1 0.4177215189873418\n",
      "./catboost_with_text.model\n",
      "Взвешанная, все 0 0.624073732718894\n",
      "Невзвешанная, все 0 0.0\n",
      "Взвешанная, все 1 0.11027848101265822\n",
      "Невзвешанная, все 1 0.4177215189873418\n"
     ]
    }
   ],
   "source": [
    "for path in models_path:\n",
    "    full_path = r\"./\"+path\n",
    "    print(full_path)\n",
    "    model = CatBoostClassifier().load_model(full_path)\n",
    "    params = model.get_params()\n",
    "    threshold = 0.5\n",
    "    model.set_probability_threshold(threshold)\n",
    "    name = path.split('.')[0][9:]\n",
    "    average='weighted'\n",
    "    params['name'] = name\n",
    "    params['threshold'] = threshold\n",
    "    test_pred = model.predict(X_test[model.feature_names_])\n",
    "    print('Взвешанная, все 0', f1_score(Y_test, test_pred*0, average=average))\n",
    "    print('Невзвешанная, все 0',f1_score(Y_test, test_pred*0))\n",
    "    print('Взвешанная, все 1',f1_score(Y_test, test_pred*0+1, average=average))\n",
    "    print('Невзвешанная, все 1',f1_score(Y_test, test_pred*0+1))\n",
    "    continue\n",
    "    wandb.init(\n",
    "        project=\"WB-reviews-classification\",\n",
    "        name = name,\n",
    "        tags=[average, 'catboost'],\n",
    "        config=params, \n",
    "    )\n",
    "    wandb.log({\n",
    "        'test_f1': f1_score(Y_test, test_pred, average=average),\n",
    "        'test_precision': precision_score(Y_test, test_pred, average=average),\n",
    "        'test_recall': recall_score(Y_test, test_pred, average=average),\n",
    "    })\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./catboost_with_text_text-class_tuned.model\n",
      "0.7697737142857143\n",
      "0.7858354561101549\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bbb1737eddb41d2b9cae93de8945710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = 'catboost_with_text_text-class_tuned.model'\n",
    "full_path = r\"./\"+path\n",
    "print(full_path)\n",
    "model = CatBoostClassifier().load_model(full_path)\n",
    "params = model.get_params()\n",
    "threshold = 0.5\n",
    "model.set_probability_threshold(threshold)\n",
    "name = path.split('.')[0][9:]\n",
    "average='weighted'\n",
    "params['name'] = name\n",
    "params['threshold'] = threshold\n",
    "test_pred = model.predict(X_test[model.feature_names_])\n",
    "print(f1_score(Y_test, test_pred, average='weighted'))\n",
    "print(precision_score(Y_test, test_pred, average=average))\n",
    "wandb.init(\n",
    "    project=\"WB-reviews-classification\",\n",
    "    name = name,\n",
    "    tags=[average, 'catboost', 'tuned'],\n",
    "    config=params, \n",
    ")\n",
    "wandb.log({\n",
    "    'test_f1': f1_score(Y_test, test_pred, average=average),\n",
    "    'test_precision': precision_score(Y_test, test_pred, average=average),\n",
    "    'test_recall': recall_score(Y_test, test_pred, average=average),\n",
    "})\n",
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кастомный класс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeReviewsClassifier:\n",
    "    def __init__(self, model_path='./catboost_full.model', get_features=True):\n",
    "        self.catboost_model: CatBoostClassifier = CatBoostClassifier().load_model(model_path)\n",
    "        self.feature_names_ = self.catboost_model.feature_names_\n",
    "        self.get_features = get_features\n",
    "        \n",
    "    def get_params(self):\n",
    "        return self.catboost_model.get_params()\n",
    "\n",
    "    def get_features(self, data: pd.Series):\n",
    "        return get_features(data)\n",
    "\n",
    "    def preproccess(self, data: pd.Series, get_features):\n",
    "        data = data.drop(['f2', 'f4'], errors='ignore')\n",
    "        if get_features:\n",
    "            data = self.get_features(data)\n",
    "            id_data = data.get(['id1_pred', 'id1_in_database', 'id2_pred', 'id2_in_database'])\n",
    "            data = data.drop(['id1', 'id2', 'id3', 'text', 'label'])   \n",
    "        else:\n",
    "            id_data = data.get(['id1_pred', 'id1_in_database', 'id2_pred', 'id2_in_database'])\n",
    "            data = data[self.feature_names_]\n",
    "        return data, id_data\n",
    "    \n",
    "    # предсказание по id\n",
    "    def id_predict(self, id_data: pd.Series, threshold):\n",
    "        if not ('id1_in_database' in id_data.index):\n",
    "            return None\n",
    "        if id_data['id1_in_database']:\n",
    "            return 1 if id_data['id1_pred'] >= threshold else 0\n",
    "        return None\n",
    "        \n",
    "    def predict(self, data: pd.Series, \n",
    "                get_features=None, \n",
    "                id_predict = True,\n",
    "                threshold = 0.5):\n",
    "        if get_features is None:\n",
    "            get_features = self.get_features\n",
    "        data, id_data = self.preproccess(data, get_features)\n",
    "        # если пользователь оставляет очень много фейков или наоборот – честных отзывов\n",
    "        predict = None\n",
    "        if id_predict and (not id_data is None):\n",
    "            predict = self.id_predict(id_data, threshold=threshold)\n",
    "        if predict is None:\n",
    "            self.catboost_model.set_probability_threshold(threshold)\n",
    "            predict = self.catboost_model.predict(data)\n",
    "        return predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./catboost_baseline.model\n",
      "0.6552185005798484\n",
      "./catboost_full.model\n",
      "0.7591067304984511\n",
      "./catboost_with_text.model\n",
      "0.6244086361242759\n",
      "./catboost_with_id.model\n",
      "0.6389769816344933\n",
      "./catboost_with_text-class.model\n",
      "0.7525990515960083\n",
      "./catboost_with_text_text-class.model\n",
      "0.7745779672706752\n",
      "./catboost_with_text.model\n",
      "0.6244086361242759\n"
     ]
    }
   ],
   "source": [
    "for path in models_path:\n",
    "    full_path = r\"./\"+path\n",
    "    print(full_path)\n",
    "    model = FakeReviewsClassifier(full_path)\n",
    "    params = model.get_params()\n",
    "    name = path.split('.')[0][9:]\n",
    "    threshold = 0.5\n",
    "    average='weighted'\n",
    "    params['name'] = name\n",
    "    params['threshold'] = threshold\n",
    "    test_pred = X_test[model.feature_names_].apply(lambda x: model.predict(x, get_features=False, threshold=threshold), axis=1)\n",
    "    print(f1_score(Y_test, test_pred, average=average))\n",
    "    wandb.init(\n",
    "        # set the wandb project where this run will be logged\n",
    "        project=\"WB-reviews-classification\",\n",
    "        name = name+'_custom',\n",
    "        tags=[average, 'custom', 'catboost'],\n",
    "        # track hyperparameters and run metadata\n",
    "        config=params, \n",
    "    )\n",
    "    wandb.log({\n",
    "        'test_f1': f1_score(Y_test, test_pred, average=average),\n",
    "        'test_precision': precision_score(Y_test, test_pred, average=average),\n",
    "        'test_recall': recall_score(Y_test, test_pred, average=average),\n",
    "    })\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./catboost_baseline.model\n",
      "0.6812413758548989\n",
      "./catboost_full.model\n",
      "0.7746631475755976\n",
      "./catboost_with_text.model\n",
      "0.6278301693860312\n",
      "./catboost_with_id.model\n",
      "0.6812178807406802\n",
      "./catboost_with_text-class.model\n",
      "0.7714258648711401\n",
      "./catboost_with_text_text-class.model\n",
      "0.785224236485383\n",
      "./catboost_with_text.model\n",
      "0.6278301693860312\n"
     ]
    }
   ],
   "source": [
    "for path in models_path:\n",
    "    full_path = r\"./\"+path\n",
    "    print(full_path)\n",
    "    model = FakeReviewsClassifier(full_path)\n",
    "    params = model.get_params()\n",
    "    name = path.split('.')[0][9:]\n",
    "    threshold = 0.55\n",
    "    average='weighted'\n",
    "    params['name'] = name\n",
    "    params['threshold'] = threshold\n",
    "    test_pred = X_test[model.feature_names_].apply(lambda x: model.predict(x, get_features=False, threshold=threshold), axis=1)\n",
    "    print(f1_score(Y_test, test_pred, average=average))\n",
    "    wandb.init(\n",
    "        # set the wandb project where this run will be logged\n",
    "        project=\"WB-reviews-classification\",\n",
    "        name = name+'_custom',\n",
    "        tags=[average, 'custom', 'catboost'],\n",
    "        # track hyperparameters and run metadata\n",
    "        config=params, \n",
    "    )\n",
    "    wandb.log({\n",
    "        'test_f1': f1_score(Y_test, test_pred, average=average),\n",
    "        'test_precision': precision_score(Y_test, test_pred, average=average),\n",
    "        'test_recall': recall_score(Y_test, test_pred, average=average),\n",
    "    })\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./catboost_full_tuned.model\n",
      "0.8004057275417966\n",
      "0.799376791643048\n",
      "0.6289308176100629\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'continue' not properly in loop (1347988152.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [30], line 15\u001b[1;36m\u001b[0m\n\u001b[1;33m    continue\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'continue' not properly in loop\n"
     ]
    }
   ],
   "source": [
    "path = 'catboost_full_tuned.model'\n",
    "full_path = r\"./\"+path\n",
    "print(full_path)\n",
    "model = FakeReviewsClassifier(full_path)\n",
    "params = model.get_params()\n",
    "name = path.split('.')[0][9:]\n",
    "threshold = 0.6\n",
    "average='weighted'\n",
    "params['name'] = name\n",
    "params['threshold'] = threshold\n",
    "test_pred = X_test[model.feature_names_].apply(lambda x: model.predict(x, get_features=False, threshold=threshold), axis=1)\n",
    "print(f1_score(Y_test, test_pred, average=average))\n",
    "print(precision_score(Y_test, test_pred, average=average))\n",
    "print(precision_score(Y_test, test_pred))\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"WB-reviews-classification\",\n",
    "    name = name+'_custom',\n",
    "    tags=[average, 'custom', 'catboost', 'tuned'],\n",
    "    # track hyperparameters and run metadata\n",
    "    config=params,\n",
    ")\n",
    "wandb.log({\n",
    "    'test_f1': f1_score(Y_test, test_pred, average=average),\n",
    "    'test_precision': precision_score(Y_test, test_pred, average=average),\n",
    "    'test_recall': recall_score(Y_test, test_pred, average=average),\n",
    "})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель\n",
      "0.6042780748663102\n",
      "0.5406698564593302\n",
      "0.6848484848484848\n",
      "0.7711823798012356\n",
      "0.7867368421052632\n",
      "0.7632\n",
      "0.7380764163372859\n",
      "\n",
      "Все 0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.624073732718894\n",
      "0.541696\n",
      "0.736\n",
      "0.5\n",
      "\n",
      "Все 1\n",
      "0.4177215189873418\n",
      "0.264\n",
      "1.0\n",
      "0.11027848101265822\n",
      "0.06969600000000001\n",
      "0.264\n",
      "0.5\n",
      "\n",
      "Рандом\n",
      "0.28813559322033894\n",
      "0.22149837133550487\n",
      "0.4121212121212121\n",
      "0.4942066140908892\n",
      "0.5699724253784851\n",
      "0.4624\n",
      "0.4462779973649539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Games\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Games\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Games\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "path = 'catboost_full_tuned.model'\n",
    "full_path = r\"./\"+path\n",
    "model = FakeReviewsClassifier(full_path)\n",
    "test_pred = X_test[model.feature_names_].apply(lambda x: model.predict(x, get_features=False, threshold=threshold), axis=1)\n",
    "\n",
    "weights = (1/(sum(Y_test==0)*len(Y_test)), 1/(sum(Y_test==1)*len(Y_test)))\n",
    "y = Y_test.copy()\n",
    "y.loc[y==0] = weights[0]\n",
    "y.loc[y==1] = weights[1]\n",
    "\n",
    "# модель\n",
    "print('Модель')\n",
    "print(f1_score(Y_test, test_pred))\n",
    "print(precision_score(Y_test, test_pred))\n",
    "print(recall_score(Y_test, test_pred))\n",
    "\n",
    "print(f1_score(Y_test, test_pred, average='weighted'))\n",
    "print(precision_score(Y_test, test_pred, average='weighted'))\n",
    "print(recall_score(Y_test, test_pred, average='weighted'))\n",
    "\n",
    "print(balanced_accuracy_score(Y_test, test_pred))\n",
    "\n",
    "# все 0\n",
    "print('\\nВсе 0')\n",
    "print(f1_score(Y_test, test_pred*0))\n",
    "print(precision_score(Y_test, test_pred*0))\n",
    "print(recall_score(Y_test, test_pred*0))\n",
    "\n",
    "print(f1_score(Y_test, test_pred*0, average='weighted'))\n",
    "print(precision_score(Y_test, test_pred*0, average='weighted'))\n",
    "print(recall_score(Y_test, test_pred*0, average='weighted'))\n",
    "\n",
    "print(balanced_accuracy_score(Y_test, test_pred*0))\n",
    "\n",
    "# все 1\n",
    "print('\\nВсе 1')\n",
    "print(f1_score(Y_test, test_pred*0+1))\n",
    "print(precision_score(Y_test, test_pred*0+1))\n",
    "print(recall_score(Y_test, test_pred*0+1))\n",
    "\n",
    "print(f1_score(Y_test, test_pred*0+1, average='weighted'))\n",
    "print(precision_score(Y_test, test_pred*0+1, average='weighted'))\n",
    "print(recall_score(Y_test, test_pred*0+1, average='weighted'))\n",
    "\n",
    "print(balanced_accuracy_score(Y_test, test_pred*0+1))\n",
    "\n",
    "# рандом\n",
    "print('\\nРандом')\n",
    "import numpy as np\n",
    "test_pred = np.random.randint(0, 2, len(Y_test))\n",
    "print(f1_score(Y_test, test_pred))\n",
    "print(precision_score(Y_test, test_pred))\n",
    "print(recall_score(Y_test, test_pred))\n",
    "\n",
    "print(f1_score(Y_test, test_pred, average='weighted'))\n",
    "print(precision_score(Y_test, test_pred, average='weighted'))\n",
    "print(recall_score(Y_test, test_pred, average='weighted'))\n",
    "\n",
    "print(balanced_accuracy_score(Y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
